import os
import re
import sys
import argparse
import zipfile
import numpy as np
from google_drive_downloader import GoogleDriveDownloader as gdd
from tqdm import tqdm
import tensorflow as tf
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import warnings
warnings.filterwarnings('ignore')
from inception_resnet_v1 import *

keras_model_path = "" 
tflite_model_path = ""

re_repeat = re.compile(r'Repeat_[0-9_]*b')
re_block8 = re.compile(r'Block8_[A-Za-z]')

file_id = {128 : "1ToPa7nrESD8B0F0ynRERM1YOVTgro5l7",
           512 : "1m4ksXmC-qsoLFWT63aVTIdKFZWqXczIE"}
dir_name = {128 : "models/20170512-110547",
            512 : "models/20180408-102900"}
ckpt_name = {128 : "model-20170512-110547.ckpt-250000",
             512 : "model-20180408-102900.ckpt-90"}

def download_model(emb_dim):
    gdd.download_file_from_google_drive(file_id=file_id[emb_dim],
                                    dest_path=dir_name[emb_dim]+".zip",
                                    unzip=True,
                                    showsize=True,
                                    overwrite=True)

def get_filename(key):
    filename = str(key)
    filename = filename.replace('/', '_')
    filename = filename.replace('InceptionResnetV1_', '')

    # remove "Repeat" scope from filename
    filename = re_repeat.sub('B', filename)

    if re_block8.match(filename):
        # the last block8 has different name with the previous 5 occurrences
        filename = filename.replace('Block8', 'Block8_6')

    # from TF to Keras naming
    filename = filename.replace('_weights', '_kernel')
    filename = filename.replace('_biases', '_bias')

    return filename + '.npy'

def extract_tensors_from_checkpoint_file(filename, output_folder):
    reader = tf.train.NewCheckpointReader(filename)

    for key in reader.get_variable_to_shape_map():
        # not saving the following tensors
        if key == 'global_step':
            continue
        if 'AuxLogit' in key:
            continue

        # convert tensor name into the corresponding Keras layer weight name and save
        path = os.path.join(output_folder, get_filename(key))
        arr = reader.get_tensor(key)
        np.save(path, arr)

def save_keras_model(emb_dim):
    if not os.path.exists(dir_name[emb_dim]):
        if os.path.exists(dir_name[emb_dim] + ".zip"):
            with zipfile.ZipFile(dir_name[emb_dim]+".zip","r") as zip_ref:
                zip_ref.extractall("models")
        else:
            print("Downloading tensorflow model from https://github.com/davidsandberg/facenet")
            download_model(emb_dim)
            
    print("Preparing keras model...")

    npy_weights_dir = dir_name[emb_dim] + "/npy_weights"
    os.makedirs(npy_weights_dir, exist_ok=True)

    extract_tensors_from_checkpoint_file(os.path.join(dir_name[emb_dim], ckpt_name[emb_dim]), npy_weights_dir)

    model = InceptionResNetV1(classes=emb_dim)

    print('Loading numpy weights from', npy_weights_dir)
    for layer in tqdm(model.layers):
        if layer.weights:
            weights = []
            for w in layer.weights:
                weight_name = os.path.basename(w.name).replace(':0', '')
                weight_file = layer.name + '_' + weight_name + '.npy'
                weight_arr = np.load(os.path.join(npy_weights_dir, weight_file))
                weights.append(weight_arr)
            layer.set_weights(weights)

    print('Saving keras model...')
    model.save(keras_model_path)

def save_tflite_model(emb_dim):
    if not os.path.exists(keras_model_path):
        save_keras_model(emb_dim)

    print("Converting keras model to tflite...")
    tflite_converter = tf.contrib.lite.TFLiteConverter.from_keras_model_file(keras_model_path)
    tflite_model = tflite_converter.convert()
    
    print("Saving tflite model...")
    with open(tflite_model_path, "wb") as f:
        f.write(tflite_model)

def parse_arguments(argv):
    parser = argparse.ArgumentParser()
    parser.add_argument('-e', '--emb_dim', type=int,
        help='size of the embedding generated by the model', 
        default=512,
        required=False)

    parser.add_argument('-lite', '--tflite', type=bool,
        help='create tflite model', 
        default=False,
        required=False)

    return parser.parse_args(argv)

def main(args):
    global keras_model_path, tflite_model_path
    keras_model_path = os.path.join(dir_name[args.emb_dim], dir_name[args.emb_dim].split('/')[-1]+".h5")
    tflite_model_path = os.path.join(dir_name[args.emb_dim], dir_name[args.emb_dim].split('/')[-1]+".tflite")

    if args.tflite:
        if not os.path.exists(tflite_model_path):
            save_tflite_model(args.emb_dim)
        else:
            print("tflite model already present!")
    else:
        if not os.path.exists(keras_model_path):
            save_keras_model(args.emb_dim)
        else:
            print("keras model already present!")

if __name__ == '__main__':
    main(parse_arguments(sys.argv[1:]))